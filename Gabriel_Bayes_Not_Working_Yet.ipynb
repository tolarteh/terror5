{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Terror5\n",
    "### Step 1. Load data\n",
    "Load csv file in a dataframe, check encoding and low_memory=False because some columns are mix types.\n",
    "Columns (4,61,62,66,116,117,123) have mixed types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['eventid', 'iyear', 'imonth', 'iday', 'approxdate', 'extended',\n",
       "       'resolution', 'country', 'country_txt', 'region',\n",
       "       ...\n",
       "       'addnotes', 'scite1', 'scite2', 'scite3', 'dbsource', 'INT_LOG',\n",
       "       'INT_IDEO', 'INT_MISC', 'INT_ANY', 'related'],\n",
       "      dtype='object', length=137)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%pdb\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "gtd = pd.read_csv('gtd_utf.csv', encoding='latin1', low_memory=False)\n",
    "gtd.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Check groups bias**\n",
    "\n",
    "Which group is responsible for the attacks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of groups = 3290\n",
      "Be careful with bias, Unknown = 45.8768%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Unknown', 71922),\n",
       " ('Taliban', 5502),\n",
       " ('Shining Path (SL)', 4548),\n",
       " ('Farabundo Marti National Liberation Front (FMLN)', 3351),\n",
       " ('Islamic State of Iraq and the Levant (ISIL)', 2833)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Terrorist group name is the target\n",
    "target = gtd['gname']\n",
    "\n",
    "gcount = Counter(target)\n",
    "print('Number of groups = {}'.format(len(gcount)))\n",
    "g1 = gcount.most_common(1)[0]\n",
    "print('Be careful with bias, {} = {:.4f}%'.format(g1[0], 100 * g1[1] / target.size))\n",
    "gcount.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 2. Preprocessing\n",
    "\n",
    "Change target classes from text to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "threshold = 10\n",
    "group_count = Counter(gtd['gname'])\n",
    "groups = [group for group, counter in group_count.items() if counter >= threshold]\n",
    "len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150816"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtd_clean = gtd[gtd['gname'].isin(groups)]\n",
    "len(gtd_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove Unknowns\n",
    "\n",
    "region2 = gtd_clean[(gtd_clean['region']==2) & (gtd_clean['gname']!='Unknown')]\n",
    "total_region2 = len(region2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove a particular group that skews predictions\n",
    "\n",
    "#region2 = region2[(region2['gname']!='Farabundo Marti National Liberation Front (FMLN)')]\n",
    "#len(region2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#group_names = np.unique(region2['gname'])\n",
    "group_counts = region2['gname'].value_counts()\n",
    "total_groups_region2 = len(group_counts)\n",
    "prior_probabilities = group_counts / total_region2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print(\"Total groups in region2 \" + str(total_groups_region2))\n",
    "# print(\"Total attacks in region2 \" + str(total_region2))\n",
    "# print(\"Attack count for Nicaraguan \" + str(group_counts['Nicaraguan Resistance']))\n",
    "# print(\"Prior for Nicaraguan \" + str(prior_probabilities['Nicaraguan Resistance']))\n",
    "\n",
    "features_used = ['iyear', 'country']\n",
    "\n",
    "data_target = region2['gname']\n",
    "data_features = region2[features_used]\n",
    "\n",
    "# print(\"Data Target Shape \" + str(data_target.shape))\n",
    "# print(\"Data Features Shape \" + str(data_features.shape))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_features, data_target, test_size=0.30)\n",
    "\n",
    "train = pd.concat([Y_train, X_train], axis=1)\n",
    "test = pd.concat([Y_test, X_test], axis=1)\n",
    "\n",
    "# print(\"Train Shape\" + str(train.shape))\n",
    "# print(\"Test Shape\" + str(test.shape))\n",
    "# print()\n",
    "# print(\"X_train Shape \" + str(X_train.shape))\n",
    "# print(\"X_test Shape \" + str(X_test.shape))\n",
    "# print(\"Y_train Shape \" + str(Y_train.shape))\n",
    "# print(\"Y_test Shape \" + str(Y_test.shape))\n",
    "\n",
    "group_counts = Y_train.value_counts()\n",
    "total_groups_train = len(group_counts)\n",
    "total_train = len(Y_train)\n",
    "prior_probabilities = group_counts / total_train\n",
    "\n",
    "#prior_probabilities = pd.DataFrame(prior_probabilities)\n",
    "#prior_probabilities['gname'] = prior_probabilities.index\n",
    "#prior_probabilities.columns = ['gname', 'probability']\n",
    "\n",
    "#prior_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total groups in train 62\n",
      "Total attacks in train 4450\n",
      "Attack count for Nicaraguan 150\n",
      "Prior for Nicaraguan 0.0337078651685\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print();\n",
    "print(\"Total groups in train \" + str(total_groups_train))\n",
    "print(\"Total attacks in train \" + str(total_train))\n",
    "print(\"Attack count for Nicaraguan \" + str(group_counts['Nicaraguan Resistance']))\n",
    "print(\"Prior for Nicaraguan \" + str(prior_probabilities['Nicaraguan Resistance']))\n",
    "\n",
    "# for feature used\n",
    "\n",
    "year_counts = X_train['iyear'].value_counts()\n",
    "total_years = len(year_counts)\n",
    "year_probabilities = year_counts / total_years\n",
    "\n",
    "country_counts = X_train['country'].value_counts()\n",
    "total_country = len(country_counts)\n",
    "country_probabilities = country_counts / total_country\n",
    "\n",
    "#ndarray, optional = np.unique(Y_train, return_inverse=True)\n",
    "#print(\"ndarray\")\n",
    "#print(ndarray)\n",
    "#print()\n",
    "#print(\"optional\")\n",
    "#print(optional)\n",
    "\n",
    "train_groups = pd.unique(Y_train)\n",
    "train_years = pd.unique(X_train['iyear'])\n",
    "train_countries = pd.unique(X_train['country'])\n",
    "\n",
    "train_groups_len = len(train_groups)\n",
    "train_years_len = len(train_years)\n",
    "train_countries_len = len(train_countries)\n",
    "\n",
    "#train_groups_year_likelihoods = pd.DataFrame({\"gname\":pd.unique(Y_train)})\n",
    "#train_groups_country_likelihoods = pd.DataFrame({\"gname\":pd.unique(Y_train)})\n",
    "\n",
    "#train_groups_year_likelihoods[\"year\"] = \"\"\n",
    "#train_groups_year_likelihoods[\"likelihood\"] = \"\"\n",
    "\n",
    "#train_groups_country_likelihoods[\"country\"] = \"\"\n",
    "#train_groups_country_likelihoods[\"likelihood\"] = \"\"\n",
    "\n",
    "train_groups_year_likelihoods = [(x, y, 0) for x in train_groups for y in train_years]\n",
    "train_groups_country_likelihoods = [(x, y, 0) for x in train_groups for y in train_countries]\n",
    "\n",
    "train_groups_year_likelihoods = pd.DataFrame(train_groups_year_likelihoods)\n",
    "train_groups_country_likelihoods = pd.DataFrame(train_groups_country_likelihoods)\n",
    "\n",
    "#train_groups_year_likelihoods.rename(columns={'0':'gname', '1':'year', '2':'likelihood'}, inplace=True)\n",
    "#train_groups_country_likelihoods.rename(columns={'0':'gname', '1':'country', '2':'likelihood'}, inplace=True)\n",
    "\n",
    "train_groups_year_likelihoods.columns = ['gname', 'year', 'likelihood']\n",
    "train_groups_country_likelihoods.columns = ['gname', 'country', 'likelihood']\n",
    "\n",
    "year_likelihoods = []\n",
    "country_likelihoods = []\n",
    "\n",
    "sum2 = 0\n",
    "for gname in pd.unique(Y_train): # for each group\n",
    "    #print(idx, val)\n",
    "    filtered_by_group = train[train['gname'] == gname]\n",
    "    #print(\"Len for group \" + str(gname) + \" is \" + str(len(filtered_by_group)))\n",
    "    sum2 = sum2 + len(filtered_by_group)\n",
    "    \n",
    "    attacks_by_this_group = len(filtered_by_group)\n",
    "    \n",
    "    year_given_group_probability = 0\n",
    "    country_given_group_probability = 0\n",
    "    \n",
    "    for year in train_years:\n",
    "        filtered_by_group_by_year = filtered_by_group[filtered_by_group['iyear'] == year]\n",
    "        attacks_by_this_group_this_year = len(filtered_by_group_by_year)\n",
    "        year_given_group_probability = attacks_by_this_group_this_year / attacks_by_this_group\n",
    "        \n",
    "        #train_groups_year_likelihoods[train_groups_year_likelihoods['gname']==gname]['likelihood'] = year_given_group_probability\n",
    "        #train_groups_year_likelihoods.set_value(gname, year, year_given_group_probability)\n",
    "        year_likelihoods.append(year_given_group_probability)\n",
    "        \n",
    "    for country in train_countries:\n",
    "        filtered_by_group_by_country = filtered_by_group[filtered_by_group['country'] == country]\n",
    "        attacks_by_this_group_this_country = len(filtered_by_group_by_country)\n",
    "        country_given_group_probability = attacks_by_this_group_this_country / attacks_by_this_group\n",
    "    \n",
    "        #train_groups_country_likelihoods[gname][country][\"likelihood\"] = country_given_group_probability\n",
    "        country_likelihoods.append(country_given_group_probability)\n",
    "\n",
    "#print(str(train_groups_year_likelihoods.shape))\n",
    "#print(str(len(year_likelihoods)))\n",
    "train_groups_year_likelihoods['likelihood'] = year_likelihoods  \n",
    "train_groups_country_likelihoods['likelihood'] = country_likelihoods\n",
    "\n",
    "#print(train_groups_year_likelihoods)\n",
    "#print(train_groups_country_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "\n",
    "#print(train_groups_year_likelihoods)\n",
    "\n",
    "test_len = len(test)\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    real_gname = row['gname']\n",
    "    real_iyear = row['iyear']\n",
    "    real_country = row['country']\n",
    "    \n",
    "    print(str(index) + \" out of \" + test_len)\n",
    "    #print(str(real_gname) + \" \" + str(real_iyear) + \" \" + str(real_country))\n",
    "    \n",
    "    gname_posterior = [(x, 0) for x in pd.unique(Y_train)]\n",
    "    \n",
    "    gname_posterior = pd.DataFrame(gname_posterior)\n",
    "    gname_posterior.columns = ['gname', 'posterior']\n",
    "    \n",
    "    posteriors = []\n",
    "    \n",
    "    for gname in pd.unique(Y_train): \n",
    "        the_prior = prior_probabilities[gname]\n",
    "        year_likelihood = train_groups_year_likelihoods[(train_groups_year_likelihoods['gname'] == gname) & (train_groups_year_likelihoods['year'] == real_iyear)]['likelihood']\n",
    "        year_likelihood = year_likelihood.iloc[0]\n",
    "        country_likelihood = train_groups_country_likelihoods[(train_groups_country_likelihoods['gname'] == gname) & (train_groups_country_likelihoods['country'] == real_country)]['likelihood']\n",
    "        country_likelihood = country_likelihood.iloc[0]\n",
    "        #year_likelihood = train_groups_year_likelihoods[train_groups_year_likelihoods[('gname' == gname) & ('year' == real_iyear)]]['likelihood']\n",
    "        #country_likelihood = train_groups_year_likelihoods[train_groups_year_likelihoods[('gname' == gname) & ('country' == real_country)]]['likelihood']\n",
    "        \n",
    "        #print(year_likelihood)\n",
    "        #print(country_likelihood)\n",
    "        \n",
    "        the_posterior = year_likelihood * country_likelihood * the_prior\n",
    "        \n",
    "        posteriors.append(the_posterior)\n",
    "    \n",
    "\n",
    "    \n",
    "    #print(gname_posterior)\n",
    "    \n",
    "    predicted_gname = gname_posterior.sort_values(['posterior'], ascending=[False]).iloc[0]\n",
    "    predicted_gname = predicted_gname['gname']\n",
    "    \n",
    "    print(\"Real \" + real_gname + \" predicted \" + predicted_gname)\n",
    "    \n",
    "    if predicted_gname == gname:\n",
    "        correct = correct + 1\n",
    "\n",
    "print(correct/len(test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Farabundo Marti National Liberation Front (FMLN)'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gname = 'Separatists'\n",
    "#year_likelihood = train_groups_year_likelihoods[(train_groups_year_likelihoods['gname'] == gname) & (train_groups_year_likelihoods['year'] == real_iyear)]['likelihood']\n",
    "#year_likelihood = year_likelihood.iloc[0]\n",
    "#country_likelihood = train_groups_country_likelihoods[(train_groups_country_likelihoods['gname'] == gname) & (train_groups_country_likelihoods['country'] == real_country)]['likelihood']\n",
    "#country_likelihood = country_likelihood.iloc[0]\n",
    "\n",
    "#print(year_likelihood)\n",
    "#print(country_likelihood)\n",
    "\n",
    "#print(gname_posterior)\n",
    "\n",
    "#test = gname_posterior.sort_values(['posterior'], ascending=[False]).iloc[0]\n",
    "#test['gname']\n",
    "#test = gname_posterior.sort('posterior', ascending=False).iloc[0]\n",
    "#test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "region2.to_csv('gtd_region2_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Choose most frequent groups as a lower index\n",
    "group_map = sorted(gcount, key=gcount.__getitem__, reverse=True)\n",
    "itarget = target.apply(group_map.index)\n",
    "# Just to test, check how to differentiate unknown from known\n",
    "itarget = itarget.apply(lambda x: 1*(x!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = gtd[['country', 'attacktype1', 'iyear']]\n",
    "unk_features = features[itarget==0]\n",
    "known_features = features[itarget==1]\n",
    "fig = plt.figure()\n",
    "plt.scatter(unk_features['iyear'], unk_features['country'], c='b')\n",
    "plt.scatter(known_features['iyear'], known_features['country'], c='r', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 3. Neural Network classifier\n",
    "Use a MLP (Multi Layer Perceptron) as a classifier of the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, itarget, test_size=0.20)\n",
    "\n",
    "nnet = MLPClassifier(hidden_layer_sizes=(1,))\n",
    "nnet.fit(X_train, y_train)\n",
    "nnet.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
