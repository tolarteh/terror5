{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['eventid', 'iyear', 'imonth', 'iday', 'approxdate', 'extended',\n",
       "       'resolution', 'country', 'country_txt', 'region',\n",
       "       ...\n",
       "       'addnotes', 'scite1', 'scite2', 'scite3', 'dbsource', 'INT_LOG',\n",
       "       'INT_IDEO', 'INT_MISC', 'INT_ANY', 'related'],\n",
       "      dtype='object', length=137)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtd = pd.read_csv('gtd_utf.csv', low_memory=False)\n",
    "gtd.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups with more than 10 attacks = 526\n"
     ]
    }
   ],
   "source": [
    "# Keep terrorist groups with at least a threashold number of attacks and remove 'Unknown'\n",
    "threshold = 10\n",
    "gcount = Counter(gtd['gname'])\n",
    "groups = [group for group, counter in gcount.items() if (counter >= threshold) and group != 'Unknown']\n",
    "print('Groups with more than {} attacks = {}'.format(threshold, len(groups)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTD length = 156772 to just important = 78894\n"
     ]
    }
   ],
   "source": [
    "gtd_groups = gtd[gtd['gname'].isin(groups)]\n",
    "print('GTD length = {} to just important = {}'.format(len(gtd), len(gtd_groups)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features defined and label binarized\n"
     ]
    }
   ],
   "source": [
    "# Define features\n",
    "feature_data = gtd_groups[['iyear', 'country', 'attacktype1', 'weaptype1']].as_matrix()\n",
    "# Binarize labels\n",
    "lb = LabelBinarizer()\n",
    "# label_data = lb.fit_transform(gtd_groups['gname'])\n",
    "label_data = gtd_groups['gname']\n",
    "print('Features defined and label binarized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitted in train, validation and test\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, label_data, test_size=0.20, random_state=1)\n",
    "# Validation data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.10, random_state=1)\n",
    "print('Data splitted in train, validation and test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_count = 4\n",
    "labels_count = len(groups)\n",
    "\n",
    "features = tf.placeholder(tf.float32, [None, features_count])\n",
    "labels = tf.placeholder(tf.float32, [None, labels_count])\n",
    "\n",
    "feed_train = {features: X_train, labels: y_train}\n",
    "feed_valid = {features: X_valid, labels: y_valid}\n",
    "feed_test = {features: X_test, labels: y_test}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One layer NN:** Equivalent to logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One layer\n",
    "weights = tf.Variable(tf.truncated_normal([features_count, labels_count]))\n",
    "biases = tf.Variable(tf.zeros([labels_count,]))\n",
    "\n",
    "logits = tf.matmul(features, weights) + biases\n",
    "prediction = tf.nn.softmax(logits)\n",
    "# Loss function\n",
    "cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "loss = tf.reduce_mean(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, nan]\n"
     ]
    }
   ],
   "source": [
    "# Run after model preparation\n",
    "learning_rate = 0.2\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    print(session.run([optimizer, loss], feed_dict=feed_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35630544993662866"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nnet = MLPClassifier(hidden_layer_sizes=(4,4,4,4))\n",
    "nnet.fit(X_train, y_train)\n",
    "nnet.score(X_valid, y_valid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
