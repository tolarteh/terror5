{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load the data</h1>\n",
    "<p>Load the data</p>\n",
    "<p>Seperate the target and the inputs</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('gtd_clean.csv', encoding='latin1', low_memory=False)\n",
    "\n",
    "\n",
    "# Seperate the target from the data\n",
    "\n",
    "targetLabelEncoder = preprocessing.LabelEncoder()\n",
    "targetLabelEncoder.fit(data['gname'].unique())\n",
    "target = targetLabelEncoder.transform(data['gname'])\n",
    "\n",
    "# requireduniquetarget = [data['gname'].unique(), list(range(len(data['gname'].unique())))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocessing of Data</h1>\n",
    "<p>Remove any features that are not required<p>\n",
    "<p>Set up data into the GTD object<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "features = data[['iyear', 'country_txt', 'region_txt', 'attacktype1_txt', 'targtype1_txt','weaptype1_txt' ,'extended', \n",
    "                 'specificity','vicinity', 'crit1','crit2','crit3', 'multiple', 'success', 'suicide' , 'attacktype2_txt',\n",
    "                 'attacktype3_txt','targsubtype1_txt', 'natlty1_txt', 'targtype2_txt', 'targsubtype2_txt', 'natlty2_txt',\n",
    "                'weapsubtype1_txt','weaptype2_txt','weapsubtype2_txt', 'weaptype3_txt']]\n",
    "# features = data[['iyear', 'country_txt', 'region_txt', 'attacktype1_txt', 'targtype1_txt', 'extended', 'specificity', 'vicinity', \n",
    "#                 'crit1','crit2','crit3','doubtterr', 'alternative', 'multiple', 'success', 'suicide', 'attacktype2_txt', 'attacktype3_txt', \n",
    "#                 'targsubtype1_txt', 'corp1','target1', 'natlty1_txt', 'targtype2_txt', 'targsubtype2_txt', 'corp2', 'target2','natlty2_txt',\n",
    "#                  'targtype3_txt', 'targsubtype3_txt', 'corp3', 'target3', 'natlty3', 'natlty3_txt', 'guncertain1', 'guncertain2', 'guncertain3', \n",
    "#                  'nperps', 'nperpcap','claimed','claimmode_txt', 'claim2', 'claimmode2_txt', 'claim3','claimmode3_txt', 'compclaim', 'weaptype1_txt',\n",
    "#                 'weapsubtype1_txt','weaptype2_txt','weapsubtype2_txt', 'weaptype3_txt']] \n",
    "# , 'suicide'\n",
    "# target1 - has approx 2600 categorical data\n",
    "# 'corp1' - has approx 2900 categorical data\n",
    "\n",
    "df = (pd.DataFrame(features)).to_dict(orient='records')\n",
    "dv = DictVectorizer(sparse=False) \n",
    "features = dv.fit_transform(features.to_dict(orient='records'))\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153011, 965)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Apply PCA</h1>\n",
    "<p> Reduce dimensionality of the features\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=200)\n",
    "reducedFeatures = pca.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Split the data into test and train set for PCA features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_trainp, X_testp, Y_trainp, Y_testp = train_test_split(reducedFeatures, target, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Apply Truncated SVD</h1>\n",
    "<p> Reducing dimensionality of the features by applying Truncated SVD\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=200)\n",
    "reducedSVDFeatures = svd.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Split the data into test and train set for Truncated SVD features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_traint, X_testt, Y_traint, Y_testt = train_test_split(reducedSVDFeatures, target, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest / PCA</h1>\n",
    "<p> Fit the data and target using Random forest classifier\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.50149875934534816"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=5, max_depth=4, min_samples_split=2)\n",
    "scores = cross_val_score(clf, X_trainp, Y_trainp)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Random Forest / Truncated SVD</h1>\n",
    "<p> Fit the data and target using Random forest classifier\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.50421464898015644"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=5, max_depth=4, min_samples_split=2)\n",
    "scores = cross_val_score(clf, X_traint, Y_traint)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
