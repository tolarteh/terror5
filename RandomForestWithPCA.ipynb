{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load the data</h1>\n",
    "<p>Load the data</p>\n",
    "<p>Seperate the target and the inputs</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('gtd_utf.csv', encoding='latin1', low_memory=False)\n",
    "\n",
    "\n",
    "# Seperate the target from the data\n",
    "\n",
    "targetLabelEncoder = preprocessing.LabelEncoder()\n",
    "targetLabelEncoder.fit(data['gname'].unique())\n",
    "requiredtarget = targetLabelEncoder.transform(data['gname'])\n",
    "\n",
    "requireduniquetarget = [data['gname'].unique(), list(range(len(data['gname'].unique())))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocessing of Data</h1>\n",
    "<p>Remove any features that are not required<p>\n",
    "<p>Set up data into the GTD object<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-4-2c969d1431c1>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-2c969d1431c1>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    ]]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "features = data[['iyear', 'country_txt', 'region_txt', 'attacktype1_txt', 'targtype1_txt','weaptype1_txt' ,'extended', \n",
    "                 'specificity','vicinity', 'crit1','crit2','crit3', 'multiple', 'success', 'suicide' , 'attacktype2_txt',\n",
    "                 'attacktype3_txt','targsubtype1_txt', 'corp1','target1', 'natlty1_txt', 'targtype2_txt', 'targsubtype2_txt', \n",
    "                 'corp2', 'target2','natlty2_txt']]\n",
    "# features = data[['iyear', 'country_txt', 'region_txt', 'attacktype1_txt', 'targtype1_txt', 'extended', 'specificity', 'vicinity', \n",
    "#                 'crit1','crit2','crit3','doubtterr', 'alternative', 'multiple', 'success', 'suicide', 'attacktype2_txt', 'attacktype3_txt', \n",
    "#                 'targsubtype1_txt', 'corp1','target1', 'natlty1_txt', 'targtype2_txt', 'targsubtype2_txt', 'corp2', 'target2','natlty2_txt',\n",
    "#                  'targtype3_txt', 'targsubtype3_txt', 'corp3', 'target3', 'natlty3', 'natlty3_txt', 'guncertain1', 'guncertain2', 'guncertain3', \n",
    "#                  'nperps', 'nperpcap','claimed','claimmode_txt', 'claim2', 'claimmode2_txt', 'claim3','claimmode3_txt', 'compclaim', 'weaptype1_txt',\n",
    "#                 'weapsubtype1_txt','weaptype2_txt','weapsubtype2_txt', 'weaptype3_txt']] \n",
    "# , 'suicide'\n",
    "\n",
    "\n",
    "df = (pd.DataFrame(features)).to_dict(orient='records')\n",
    "dv = DictVectorizer(sparse=False) \n",
    "output = dv.fit_transform(features.to_dict(orient='records'))\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Apply PCA</h1>\n",
    "<p> Reduce dimensionality of the features\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=275)\n",
    "reducedFeatures = pca.fit_transform(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest</h1>\n",
    "<p> Fit the data and target using Random forest classifier\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=1, max_depth=4, min_samples_split=2)\n",
    "scores = cross_val_score(clf, reducedFeatures, requiredtarget)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
